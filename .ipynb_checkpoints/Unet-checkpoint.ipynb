{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Implementación Unet</h1></center>\n",
    "\n",
    "---\n",
    "\n",
    "Tutorial: [aquí](https://becominghuman.ai/implementing-unet-in-pytorch-8c7e05a121b4)\n",
    "\n",
    "Este tipo de red neuronal esta principalmente compuesta de dos partes, un bloque de contracción (_**parte izquierda**_) y otro bloque de expansión (_**parte derecha**_). Posee la siguiente forma: <br><br>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./Ilustraciones/Unet.jpeg\"/>\n",
    "    <figcaption>Imagen UNET</figcaption>\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<p style='text-align: justify;'> \n",
    "La parte izquierda es solo una simple <i><b>red convolucional</b></i>. En cada eslabón de esta parte de la red existen dos capas de convolución (3x3), cada una seguida de una función de activación Relu, y luego se aplica una capa maxpool (2x2) (flecha      roja en la imagen). Notar que la primera barra vertical en el lado izquierdo de la imagen no es una capa, sino que representa la entrada (imagen de entrada).</p>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    " En la parte derecha de la red es donde suceden cosas interesantes. En esta sección también se usan dos capas de convolución de (3x3) apiladas juntas (secuencialmente) como el lado izquierdo, pero no se usa la función de activación de <i>ReLU</i> y no se usa una capa maxpool. En su lugar, se usa una capa de convolución transpuesta (2x2) (flecha verde en la imagen). Durante la ruta de expansión, tomaremos la  imagen (copia) del lado izquierdo y la combinaremos con la imagen de la derecha (flecha gris en la imagen). Recuerde que también se utilizan capas de convolución secuenciales de 3x3 en el lado derecho, por lo que la entrada para eso será la combinación de la imagen de la derecha y su capa anterior (la mitad del cuadro blanco y azul en el lado derecho de la imagen es la combinación). La capa de salida en el lado derecho se aplica una capa de convolución adicional (mapa de segmentación de salida).\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloque de contracción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia implementaremos una función llamada `dual_conv()` la cual se encargará de contener las capas convolucionales y de polling de izquierda de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_conv(in_channel, out_channel):\n",
    "    \n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3),\n",
    "        nn.ReLU(inplace=True))\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar, implementamos una clase `Unet` la cual se encarga de contener la parte izquierda de la red. Llamaremos `dwn_conv_n` a las capas convolucionales de la primera parte de la red, debido a que en la imagen aparecen ilustradas como flechas que apuntan hacia abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        self.dwn_conv_1 = dual_conv(1, 64)\n",
    "        self.dwn_conv_2 = dual_conv(64 ,128)\n",
    "        self.dwn_conv_3 = dual_conv(128 ,256)\n",
    "        self.dwn_conv_4 = dual_conv(256 ,512)\n",
    "        self.dwn_conv_5 = dual_conv(512 ,1024)\n",
    "        self.maxpool    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, input_img):\n",
    "        \n",
    "        x1 = self.dwn_conv_1(input_img)\n",
    "        x2 = self.maxpool(x1)\n",
    "        \n",
    "        x3 = self.dwn_conv_2(x2)\n",
    "        x4 = self.maxpool(x3)\n",
    "        \n",
    "        x5 = self.dwn_conv_3(x4)                                \n",
    "        x6 = self.maxpool(x5)\n",
    "        \n",
    "        x7 = self.dwn_conv_4(x6)\n",
    "        x8 = self.maxpool(x7)\n",
    "        \n",
    "        x9 = self.dwn_conv_5(x8)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el código anterior la parte _**izquierda**_ de la red esta completa, ahora debemos codear la parde __*derecha*__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloque de expansión\n",
    "\n",
    "<p style='text-align: justify;'>Para comenzar a implementar esta sección, debemos añadir las convoluciones transpuestas y las capas convolucionales de \"subida\" a nuestra red. Por otra parte, como vimos en la imagen de la arquitectura, las entradas de cada bloque de la parte derecha de Unet corresponden a una combinación entre las salidas de los bloques del lado izquierdo (flechas grises) y la salida de la capa anterior. Para combinar estas entradas debemos hacer un <i>resize</i> para que tengan las mismas dimensiones, por lo que implementaremos una función crop_image() con el fin de re-dimensionar las imagenes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_tensor(target_tensor, tensor):\n",
    "    \n",
    "    target_size = target_tensor.size()[2]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size\n",
    "    delta = delta // 2\n",
    "    \n",
    "    return tensor[:, :, delta:tensor_size - delta, delta:tensor_size - delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        # Parte izquierda (bloque de contracción)\n",
    "        self.dwn_conv_1 = dual_conv(1, 64)\n",
    "        self.dwn_conv_2 = dual_conv(64 ,128)\n",
    "        self.dwn_conv_3 = dual_conv(128 ,256)\n",
    "        self.dwn_conv_4 = dual_conv(256 ,512)\n",
    "        self.dwn_conv_5 = dual_conv(512 ,1024)\n",
    "        self.maxpool    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Parte derecha (bloque de expansión)\n",
    "        self.trans_1 = nn.ConvTranspose2d(1024,512, kernel_size=2, stride= 2)\n",
    "        self.up_conv_1 = dual_conv(1024,512)\n",
    "        self.trans_2 = nn.ConvTranspose2d(512,256, kernel_size=2, stride= 2)\n",
    "        self.up_conv_2 = dual_conv(512,256)\n",
    "        self.trans_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride= 2)\n",
    "        self.up_conv_3 = dual_conv(256,128)\n",
    "        self.trans_4 = nn.ConvTranspose2d(128,64, kernel_size=2, stride= 2)\n",
    "        self.up_conv_4 = dual_conv(128,64)\n",
    "\n",
    "        #Capa de salida\n",
    "        self.out = nn.Conv2d(64, 2, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_img):\n",
    "        \n",
    "        # Paso hacia adelante (lado izquierdo)\n",
    "        x1 = self.dwn_conv_1(input_img)\n",
    "        x2 = self.maxpool(x1)\n",
    "        \n",
    "        x3 = self.dwn_conv_2(x2)\n",
    "        x4 = self.maxpool(x3)                               \n",
    "        \n",
    "        x5 = self.dwn_conv_3(x4)                                \n",
    "        x6 = self.maxpool(x5)\n",
    "        \n",
    "        x7 = self.dwn_conv_4(x6)\n",
    "        x8 = self.maxpool(x7)\n",
    "        \n",
    "        x9 = self.dwn_conv_5(x8)\n",
    "        \n",
    "        # Paso hacia adelante (lado derecho)\n",
    "        x = self.trans_1(x9)\n",
    "        y = crop_tensor(x, x7)\n",
    "        x = self.up_conv_1(torch.cat([x,y], 1))\n",
    "        \n",
    "        x = self.trans_2(x)\n",
    "        y = crop_tensor(x, x5)\n",
    "        x = self.up_conv_2(torch.cat([x,y], 1))\n",
    "        \n",
    "        x = self.trans_3(x)\n",
    "        y = crop_tensor(x, x3)\n",
    "        x = self.up_conv_3(torch.cat([x,y], 1))\n",
    "        \n",
    "        x = self.trans_4(x)\n",
    "        y = crop_tensor(x, x1)\n",
    "        x = self.up_conv_4(torch.cat([x,y], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd81c3ebcf0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(17) # Semilla fija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((1, 1, 572, 572))\n",
    "model = Unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_1 = tf.Compose([\n",
    "    tf.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.4069, 10.1751,  9.9227,  ..., 10.3516, 10.0408, 11.0575],\n",
       "          [10.9849, 10.0009, 10.7957,  ..., 10.5048, 11.2008, 10.6411],\n",
       "          [10.1083, 10.3620,  9.0932,  ...,  9.8431, 11.2205, 11.4161],\n",
       "          ...,\n",
       "          [10.6583, 11.3944, 11.5135,  ...,  9.9940, 11.2676, 10.0746],\n",
       "          [10.6842, 11.8634, 10.8824,  ..., 11.9543, 10.2457, 10.2677],\n",
       "          [11.9618, 11.5878, 11.6197,  ...,  9.7759, 11.1954, 10.0936]],\n",
       "\n",
       "         [[ 4.2891,  5.6255,  5.4031,  ...,  5.5661,  4.8545,  5.4203],\n",
       "          [ 4.5851,  5.4328,  5.5153,  ...,  5.2368,  4.5125,  4.4686],\n",
       "          [ 4.1980,  5.7457,  5.6489,  ...,  5.6873,  4.6730,  4.8092],\n",
       "          ...,\n",
       "          [ 5.4458,  5.3387,  4.0830,  ...,  4.9310,  4.9733,  5.1101],\n",
       "          [ 5.0306,  4.4291,  5.1857,  ...,  4.9802,  4.6121,  5.1998],\n",
       "          [ 5.1001,  4.7026,  4.4838,  ...,  5.2022,  4.9927,  5.6578]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out= model(img); out*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.reshape((2, 388, 388))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 388, 388])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_PIL = transform_1(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjJklEQVR4nO2dbexnRXXHv0dY0FYj4m43W0FAu43Bpq5IcU1NYzVW5M1iYs3yomwMCbbFRJOmKbRJq0lNtKmSkLRYjVRsrIhPYdNgLSJJ4wsXEFdcwJX1KbJZ2aCCGlNa2NMXd+5yudyHeThn5sz93U+y2d///u7vzpmnMzNnzrlDzIyVlZXN5VmlBVhZWSnLqgRWVjacVQmsrGw4qxJYWdlwViWwsrLhrEpgZWXDUVMCRHQxER0moiNEdLVWOisrK2mQhp8AEZ0C4DsA3gjgIQB3AbiMme8XT2xlZSUJrZnARQCOMPP3mPl/AdwEYI9SWisrKwmcqvTcFwH4UefvhwC8euzmrVu38jnnnKMkigxEhNW7UpallulUvnzzrFE299xzzyPMvK1/XUsJzEJEVwK4EgBe/OIX48CBA76/y95wiAgAnpauthyhz+/fryEfM58sixUdhtpa+3dq2W/ZsuWHQ9e1lgNHAZzd+fssd+0kzPwRZr6QmS/cunWrihBSnYCZBytFk9DnazSaPrkUwCYrmqG2BuiWiZYSuAvATiI6j4hOA7AXwP7Yh3ULIHR07CPReX0UglalbUIHqWWJoFXvoc9ITVNlOcDMTxDROwF8CcApAG5g5vsSnicil1QH8nmOVkMOeW7O5UtOxvKSO49E9Iw0NQYZ6fv7qNkEmPlWALdqPT8GrQYypBTaxjHXMFMbrm86PvfUwlgeYvOWUi5zv6uhzBfnMWhlutxW/FwDSG0gvulIp5uClTrSInb5WorFKYFUm0FuQmVIGe1S0pXEWsfQ2EUJJaY+xn4Tmr45JeBTGFINuC2slOf5FPjcND2E7vQyRO4xq/OmYUHxDxFTN1O+CCGYUwKpnUorzTFyKq0+sbMeqx1BC+3peclZlkT7M6cEYmkttbUTm4e530lbsFNJrauUXZKUZ6XKIsXQzsQYc/csRgksZbrr61Ia87uY52r+NkRxzf3WN/25vX2JgSRHO5Rs74tRAivppDSqmN0Jn+01X06cOBGU/lg6EnaisWfnxrdOViVgiFwzmVrdibVk8C33mDRS6zTH7GxVAobI1ZlyGFZzLy2kGcpTieVmjjRXJeCBdkWUaPTaaaYEMJXYIRqyMZSIA5BKKyTdapWAlW0YKUNSv1FbGA1jkNiFkNx2jTUYSkagphKjkELSrVYJWNgJkPQL71eytIGqn5bWWlVibS5ZtzmNnVr47gTEylutEhhCe4qonV6uNOb2zUOfIYX27Kd9fq2zLB9ilPOilMBYNF8s2h3QAtbk0URjppGKtJNbTIRlVUpAcoumVEMo+S6CMZY8MmoR4sg095zSSqkqJSBZWJYbfu5Q1NKNMAapMko1Xg6N5L6BPVbaYFVKYIxchSm5fpa2bqditYGOEWLX0NzdCRnJ+zJbUb5VKYEcDdM37DdEFi1f/5D05pjbIrOuFKaw0tm6pJSvdF1UowSmNKdk8ExKIIoVNsGgmdoRrCk1ra1mH5KUABH9gIi+RUQHiehud+1MIrqNiB50/78g4Hmj32mFe6ZMJXPSyiH1Iom5dCw8S/JlLEB9r/0aQ7pcJGYCf8jMu5j5Qvf31QBuZ+adAG53f3uhNYL5bMOEzDJKdrix38SsS8e+t6b4pKi542uisRzYA+BG9/lGAJcqpOHNnAFG4rVOoc+YG9V90owl1xZlDsOX1vNrUBaSCjJVCTCA/yKir1NzrBgAbGfmY+7zjwFsD31o7pEo9/qyhkaWSo48xjqHzblkl5oJlRgUgPRzB17LzEeJ6DcA3EZE3+5+ycxMRIPSUu8swt7vEsXyox2tpINFfOwMMbMH68rDgow+6cfMxHIgbY/J8lIRZj7q/j8O4AtojiR/mIh2OEF2ADg+8luVswhDvbUk8XUBnUs395aiFDXImINcPhdShvRoJUBEv05Ez2s/A/gjAIfQnDm4z922D8AtsWkEygOg7JtcpLDemSyUkWVSbUa+EYNSy4eU5cB2AF9wDeJUAP/OzP9JRHcBuJmIrgDwQwBvS0jDmyFvrJjpqfUOWBoLU/6lI/k+BZ/7o5UAM38PwCsGrv8EwBtinzuS1jPemiIdX21pa0wKjQ6rsYSa270ptVZeElVGEfY7fRefve4Qug3NuqU/ZQqo4QgU+0zf5Zs1X4FaB4opuc0qgZydK8STrHSgTUp6ko5P7bNi60mzfmt9dinMKgGrLKURWN0mk6DW0boUZpXA0irSmmPKUlmiUuuzMVGEJSszZxRernymbltZpfTyrE+OcpVOw6wS6FLTujvm+RpbQtK/t4o1ZVbyvQCxVKEEtMldGWNvmJnzALPSaCygGcmZq5ytvFimCiVgKRpNc8tqThlYG/VSSClHyToYKtPc5ayhdLK4DVsgh8buumeGOJps4qidK25DMuhLkinflql7Sjt0Va0EcjiadIOCckWoWWzgVqhFuUp7tIYQWkZVKIHUuPGcaKfpG6lYghxKuZSClGpvFhV8FUpgat1mtUNoETMVttLwSk97LaVlabfHrBLwzaSmf3wppPO0hDIZouZ8pSoVSYOmWSXQ30bzYchwp9FQtPeCc7+EwurSShvLS6sYYvNiVgnM4fv2nZzefz73xsgj/fqz0Ocv1UehXVqN5d9CnruKSkueKpSAhb3cLilhzhYalg8xM7E5fBV3v3xDZoJSco3JlpuuktKSpwolYI0hB58WzU5eiwIJYU4xzBlCS9VFDnIpoVUJGMTCyJTLGKmRjoUw6al8+U7vcymxapWAdgEtLYoRkHOe8sF3CRfigOVLiboLWRb2p/elZyyzSoCIbiCi40R0qHNt8LxBariOiI4Q0b1EdIGW4FIVvUnTd4kyy9XBuqOlhbX5HGPG0xociHxmAh8HcHHv2th5g28GsNP9uxLA9TJiPh3tAJKQNOYi/3yRVhjWFFAo2sYwn7Rjf6dhVI2RY+zvPrNKgJn/G8BPe5f3YPi8wT0APsENXwNwBrmDSCSxNAuQkEUj8Kb06FIzWvaQuZ0OjV0Yn+3dWJvA2HmDLwLwo859D7lrJrGwP9xOd0tGJ+aKyqt9dpLKWDlrBp35lHmyYZCb1IOlJ6IriehuIrr7kUceSRVDFAs+6ZIy+Fihc4VlrzwdKZtHSv3FKoGx8waPAji7c99Z7toz4M5ZhNu2bYsUw5/aRiFJLzFLna+2etgEYpXA2HmD+wFc7nYJdgN4rLNsGMXCtDwnGjYAK2jXWUr8g0Ra0g5JFlyyZ48hI6JPAXgdgK1E9BCAvwPwfgyfN3grgEsAHAHwKwBvTxUwZLo0VaB9i61k5wqtyFL72Jr+B77W/FgZ5mwnElF5Pnv9oW7ivmmXZFYJMPNlI18947xBZx+4KlWozvOC7k9xZEkhtyafUzpDhqap2ZamgpTy3vOVf+q7uXstEZKv0O/7mPMYtFYZFplylQXCrP1De8qpHnqxskgy1BFKj7g+tEZa33iJmO/7mFMCWtPJMZaidEIdVFIaWcqztdCYppeghNI0pwTmkO60PlPmXLJIoeGPL/17Kbq2CB+ZcjjrtNSiiKpTApqENpBaKlkDixF6qYY8S7PM2N/G5KFKJVCTP3kufBx+YhpWrt+E0F/69NOzMktpiZEnZRclVIYqlcCcYWzsN9Yaxxi+I12oAS6mYcX+Rltpdncdco7uPli0T0zJUKUSGMKnA5SewqZuYVpsXGPknA1MfVdinS89imuzGCVgmdi98pBpbi2znC4hMkuvkUPror1fsw58Ha6miJFhVQIZiJ2FhOxz5ww4kqLkbkzos1K3XUOemZLPjTEMLhkLU3wLMvSRWs5ZmjFZKWdzSsBKweQiZcqv2aCl3H0lWVpEpRXMKYFuRfsa02qu2BDZU91gY9JaR87lY04JtISMRKWs5rE+9qUac65w21xpa1CLnICcrGaVQApSVlqp+1okXxQy9FwNpHwPahnFpeSUcMuee4aUrGaVQKohKGVNm/PFFSGMucVqdsTSefYlJW8aeawpCMusEkhFY01bejRLjV+opUPHkOKaW7pex8gl12KVQA1Y6pQa++bWWUIegGca0+fu6bMqAQV8KgVI1/RasxypHRlN555N3S4cktknHH6xsQOp8eNaSDauEsExUs/VLAdrHThXO9OISIw9i/A9RHSUiA66f5d0vruGmrMIDxPRm4IlDkAzmENKBkujfQlyy1+qvDTbmfYLYGLPIgSAa5l5l/t3q0vsfAB7Abzc/eafieiUIIkLUOLlD5vC2I6GVrlZmyFIoJ2n2LMIx9gD4CZmfpyZv4/m1eMXJcinTrvFZnG/O+a9CTWwxI4aiiW37BSbwDupOX78BnJHk8PIWYQhHcV3K7GEG+2cEWiO0FDdHLEJMdtyS1B8fSy5ZccqgesBvBTALgDHAHww9AE0cBZhaqNP+c0cFiprjv6uRGisQI63AWkYtmKxWKdDuzTackYpAWZ+mJmfZOYTAD6Kp6b8UWcRbt26FUD8++wsVqYUMbOa/udYpDufhalvF2l5JNph9xm5nJmilAC5w0gdbwHQ7hzsB7CXiE4novMA7ARwZ5qI9eCrkGI7ttQzQymtZEun70uO14pplEXsWYSvI6JdABjADwC8AwCY+T4iuhnA/QCeAHAVMz+ZImCuIIpUtH34tZ/JPPze/thGF7ocmcJKHfsQk++QmBCVpa6FAn7Vq17FBw4cSHqGr7VVsnHmeG5Lt5OOdVhpeaae4SODhCwh6ZQmNp+5dgq2bNnydWa+sH+9ao/BLr6GLetedmP4uiK3aFvfQ5Y9FgaalpJh11O/667/c5eXKSWQK4hFoyHMba9ZHs1i/M1TnuvLkI0lNMahf691hRRj6E7NkyklILGW0vxdyDMtNbaSpCi/sbXy1Pchzyr9G6k2MrcMmVMsZpSA5ZFSgpTtuynHktRy0/Z5r1kZai2T+kiU0VS6c0sMM0qg5saizdRUNjXKMHZk9cHHSBty3RpSy9HS+TWjBDaJXLaMXDaWWLRsEbnyYWk5msLilYC1Ak8hdvtpqlNIe7lJ3hvLprqND+Ej9+KVgHTl1dYY5taDudyLQ/w4cuKbXq2DiY/cZpVArjDaEIcXwEZjiF1TSrs0hyDpTSlpSAu1m0jcp0mMDGaVQC6XSV8sdP4xSnSwkg1ewtahsZUXW3aSZRnTTs0qgVzEuqWW7AQWFFKo086ml1cXa/JsvBIA4jS4tYoMIdQFeQ7tKXxOBVJCWZVuS6sSCGCssko0HClPvNwN0NJLRUqnZYVVCQgw5dGnnWZtaHsoWsei0l2VgCBz/ttLweK2awmZarAlVb1FWCtjlWx95J5y4Z2K5JPA4q6Pz+zOep36slglUKqCpNPN5S8x1RlqaOyxctby5ipNFqsElmLJr1l2a+SIpfB549PQ7Er6RTG+zwQWogR8Cr5m5qbjteevi2ZodI73VczZhdoZS8z7J7ReNuJzFuHZRHQHEd1PRPcR0bvc9TOJ6DYietD9/wJ3nYjoOmrOI7yXiC4IkjyCnK/2Gvpbm7n8LWm2kDraWVaIVuvJZybwBIC/YObzAewGcBU1Zw5eDeB2Zt4J4Hb3NwC8Gc2rxncCuBLNQSVmiLH6rm8NKk9ug6tlZSKNz1mEx5j5Hvf5FwAeQHO02B4AN7rbbgRwqfu8B8AnuOFrAM6gp59TkI3Y+ANLndxaYywlT+460X7bjyWCbAJEdC6AVwI4AGA7Mx9zX/0YwHb3Oct5hHNx8u09GumOoRGWa0Eh+RpZNdfzNSIdeKSFtxIgoucC+ByAdzPzz7vfcZOLoJzQwFmEIZTautJ2CLI4egzlOTUybwiLeQf05dJ+6cscXkqAiLagUQCfZObPu8sPt9N89/9xd93rPEIeOIswBJ+ZQMwztdB6dqnnWvHDyNFJYgLMpOTKUc4+uwME4GMAHmDmD3W+2g9gn/u8D8AtneuXu12C3QAe6ywbZvEtPKmZQC6/f63KlNg79hnVrQT++HgvSuzvhw4y7fZfjcyeRQjg9wH8CYBvEdFBd+2vAbwfwM1EdAWAHwJ4m/vuVgCXADgC4FcA3h4iUBvfn6tAQ52KpmSroSGEGku7e9u+tL/JNUpLuDX3348w94z+PbltOUMy+l7rM6sEmPmrAMZq8w0D9zOAq+aeO5Pm0/7O0bkkjDjWFUAMMXWRsxx8t3xDZBpTlLm8UGPjFmL7TRUeg1Mjb2ksyJCTXCO8VBrWnuOblkR6Yh6DlrEQfWZh9K9xDz1XGrUEQJWkWiVQegTOlX6IT/nSG3vpOl8qppRA6rotJyUMl773jkWq1U5qmZduM32ktxFj82dKCdTUaHM5kMRuza3T4GeSUqa+lBjIUvNlSgnMYUlJaMcghGh3S+XSJYeiDElDw44TGsVosa7MKgENt9RYfB1sYu5JlQOwN81t0d5OjfFfkCY0HxYDk8wqAUsN24os0iNYyVHpWc8ab3oWR0sfQpV0bD6l26NZJSBBrY0pFzE+8an3+exk5FS6Eu7Rc3mSnMFplM2ilYCVEdwSmtuJ2nYSDaZcjn0Dgqx5SIayCCUQsmbP/Y4BTSz5KrTE2k9Cie14sdZ7iUAtqyxCCYQExeQcAS1GJpaIwZBedoTeK/G7UKzNeKZYhBKwSsmYe0m321CsGLw2kZiyX5XAApG0/Ic+J2cYcQqW5ZPwLwnBhBLIMQ3cdKbKTbJMJaztEr+dw9qsY8ggOabMF+knMPdSC997tcjhbhpKqCwhW3KSYayp9WWpzDUZc45LsbHMPb/FhBKYIscbWubStxQ23JLjpRYSLKUT51pe+exqxfhtTNWpeSWgzdi+cOg1CUpsX6YGKknIMPX8kFmidPqxpPgU+Oxq+c7cNuKlIqWYmhn4NgCpad4cvo2uf59k4FLJmA8pm4TlMPfU9FLOInwPER0looPu3yWd31xDzVmEh4noTUkSZkTCIcR35LI+TS7ReULxUXAp26VasueONJzLh8/bhtuzCO8houcB+DoR3ea+u5aZ/7F7MzXnFO4F8HIAvwngy0T028z8ZLD0hmm3wuauxTynBqa2AWMNVyVnDKFekZrbeNLlMKdUUs4iHGMPgJuY+XFm/j6aV49f5C2xIJqRcr7TeR/DYwli042xIfjcW1IRSocDa9pXNH6fchYhALyTmuPHbyB3NDkynUXog5RhaQqrnXyOnF592gbEEHKkEdPmUuVK+X3KWYTXA3gpgF0AjgH4YEjClHgWoWcaKs/tYrWT10iOGIzS9ZUajKVB9FmEzPwwMz/JzCcAfBRPTfnFziJMDd+UWHut3ox6hO4uWN0S1ELDiWuI6LMIyR1G6ngLgEPu834Ae4nodCI6D8BOAHfGCJc6lZfw9Dtx4oS3DNas0NaJXYvHKPclKAatdpJyFuFlRLQLAAP4AYB3AAAz30dENwO4H83OwlWldgZ8Gs2cpTd1NuKD1QZqdedC2vBWQ8BTl5B68bk35SzCWyd+8z4A75t7tiSxDXZqHdo2jtIdwUcGXzlD8uNrBe97XZYur1C0FYC0kpnyKoxJZzEeg9INLyReQHK/PPY5vh5/kg1yaPdFWwHk6EzSFnwpx6uYe33qYzFKYA7NiphrTCWmmjmWMSWQlD1UeZew7Esbr4dYlBLQavipFVFjp8upuGpaj08h6S4t0WZ8y3VRSmBJXmelsS5fafp2EGlbSIhiTJ25mFACSxkJQsiV51g//lhKuMyGIu0p6hukpOnGnoIJJVAycKQ02h0uR6fs3h8TQLV0ursoudp6SLmaUAJAGUVQesqbul1XWn5geHSb+7vLUuq95jyaUQK53XNLWu5bLHTiUHy2BHNvG1pgaOtVK9/SzzWjBMaI3fv0vT+1QHMpESvT5tz2gprp5lcy79LlaF4JSKwxJRTJGNZHOUsdz3pZpRI62EzVTc56M68EptDs3DXS37bqXxtCurFZUjqxWNi5CYkN2GhnodgOP7R2k4pln5uJSHXOuXRKWemXpoR9Z5alkNhxqFoJxDIUpy3l/z9nKPONjfcJl5VojDk90zSRtO1MbXn6djqpIK0cbJwSSG2wFhq8BmNrVp/8WmjIqcE9IdPvEvdpUoUSyBE5luv3kgzNaKSfXyrWPve63EJnLIVpJRASzlsSSR+HlMZYy760xfRLpFG6XFtMKwFL2jnEC65/j4/BLnRaGoNWeU7J7GNrmdvlsdQOUohpQzkwrQQsMaXF517gIWlISkErHj7GZVYy7NZHjpVxViWgjHTnXhv6OKXsF9KkvtkotAx83jb8bCK6k4i+Sc1ZhO91188jogPUnDn4aSI6zV0/3f19xH1/bpBEysRG3sU0Lo0GmevtNhLKq4QRNuc6O8TjLyRWxef9AFNLi9Ay8JkJPA7g9cz8CjQHjVxMRLsBfADNWYS/BeBnAK5w918B4Gfu+rXuPjPETs2lGmTORhqzVpekpu3Y2JBrX/8SaSO3pJHR5yxCZuZfuj+3uH8M4PUAPuuu3wjgUvd5j/sb7vs30BLmaEJYKQrJ7UXp9b3F0FspZ7ISzMnoewLRKdScOXAcwG0AvgvgUWZ+wt3SPW/w5FmE7vvHALzQIw0fUZKeYaUDWiSlMUtb8q3Uk69ysyLvGHPyeSkBbo4b24XmSLGLALxMQLCnnUWYYwQppbWl/fitN7qlIO36a7XegnYHmPlRAHcAeA2AM4ioPbyke97gybMI3ffPB/CTgWfNnkWoRe6gkNBn51Jmqdbmko3aaodqCfERKY3P7sA2IjrDfX4OgDcCeACNMniru20fgFvc5/3ub7jvv8JWc+/w3cvPQYjFuSVW9jHDZT8dH2v10og1FPY/S5aRluLzOYtwB4AbiegUNErjZmb+DyK6H8BNRPT3AL6B5tBSuP//jYiOAPgpgL0Kcidh1X0TiIsxH5vZxOQr9+9i6XaylOChvj0jpfP2R32NWI6hck5Ny+cswnsBvHLg+vfw1HHk3ev/A+CPYwWyNCrHYsFpJXcZlqozLV+I1HYY6nGZYn9IbWvmPAZrbExSPuFWLeu1K2Ug3EnHij/HEL5LRt+2YEIJ5PLGi/Fx9yG1wUgGD02NFD7KauieJRgAx8ql9IwtBt8lo297MqEEYoiZFsXu9cZ+54v2tHNsnevj0Vh6FqC5/cYsdxhIaRftFDlMKAEtV0rAv1BiDHJD32mMLFozGG1yjrIlyiF0+y/HVmtMOZhQAkCZWPfcSG7lLQ3tOIOQAB5fQusldz1WZRMA8hRQ6fVf6fRzE1KnqfXv62C1CQo1FDNKIIQYCyiQZ+q+lEa2KQprU/I5RZVKoO1o3f3VVA+vUJbeeEors6WXbx+N8l787gAQX3ClLfqlKBkOKx0/EfuMIZdo6a3CXFveUlStBLrkXH/6kLNSU3dAcuxoxMbrS8owJod0e6htgFiMErBGSY8zC1Np65bzmPQ1HZdKsiqBBSL9/oKlELsckvTobJ8n4Vwk5T9iXglY0Zqa67zS7quxjlIttSiR2OVQSaPdED7lHVIn5pVAaAOz5HQUEhlmRdnFULPsNSNV7uaVQEus8Sv3KCUVjWhldLUiRwg1ylySapRALS63KS+jKBXKKoGljlebUbI01SiBGCw1zCn6b7fxRfsFLL7++EDdHamED4MW1UYRapGrskoFpYy9wSik8/rcnxtr8vSxLF/VUYRa5Kiw2PcUaBFqBY+V3zdoJxSf31kejUsRWyYpZxF+nIi+T0QH3b9d7joR0XXUnEV4LxFdECWZEBp75ta8E4G0l4uMPSdl12JollLaNdfnOaW3a6cIneH54vO24fYswl8S0RYAXyWiL7rv/pKZP9u7/80Adrp/rwZwvfs/GO01r2R6uWXto/lilhimXHbHljEliH2Tkk99S7cJSYXcJeUswjH2APiE+93X0BxSsiNA5m7aQddTiXmVlZQ3mZVOkQNLeY0d+WtasszlL+osQmY+4L56n5vyX0tEp7trJ88idHTPKRTBQiOSdiW10mC0KbUkmBpQJKJRLbTJWKLOIiSi3wFwDZozCX8PwJkA/iokYeqdRZiL3J12KZ1bKgqw1PR4Sr5Yr9Sa/Tq6xJ5FeDEzH3NT/scB/CueOojk5FmEju45hd1nzZ5FmCu8VOpZY7HqSyCXf33Kc3z9LULDnMfSsWxEDCH2LMJvt+t8akrhUgCH3E/2A7jc7RLsBvAYMx9LFTTFE0+LMaNSm26o48/Y9dwW7JINW8rtOjYoaqoehp6zBO/ElLMIv0JE2wAQgIMA/tTdfyuASwAcAfArAG+PFS7Wk27o9zmRDDYauq6dr5ht1XbWU7qRp8oQaowOTc+nHefeeUg5i/D1I/czgKvSRYsntoAsNOIhUuXSzpeP/0Hsc4dmQbGjvAYa6c3NVFKMmUMs0mMw1VPN2jrPsgLQZMrXYMmkeGnGsEglkIrVhia5zPDFmkIsRc5yyN3+Nl4JxFRujgYx1BCk0rXo9rxSjo1XAiVGVx98O7xVJVYiLc30tOu85IyrOiWQuj7WvF+C0DSnrNbS1LBDoxn7oImP3NLBbS1mlYBG4x4z/I09s8RUOKfTzZxDTapTjQ9jdVFaiUnkVWO3ZI6YcjOrBDQ1cWzkWEk0ymNuqy1HuYzVhYYyzO2yXMuyy6wSaFmt0w0WR6YaqKH9SMiYojzNK4ElNdzSDbKUTcSCbUVChqGoQckOLEFMZKN5JaBBqc5Yg0Lr2gIsBAWNERrQpDWTkghD1sJXto1UAtb3yUsqi1RbgKZhr0tp1+HUNCwNCBuhBGIbpGa03tS0rYatzDlSg7/mnjlFjvIouXOS+pw+JpRAyVHD93ex+/c+UWlLGlU0ox411vlSSMsyFPMh0Y6HMKEELGn4sTRjwmu7/0/dsymU2DcPxUqd5FTsJpSAL74FM3dfrj3wOTSDe6w05i6S8mr5TWi2C993CeTGvBLQ8I0PWetbUBZjlDKO5Y6h12Co/rXf1jT0foQ+JdobWWjkRPQLAIdLy6HMVgD53qianzV/9jmHmbf1L/q8XiwHh5n5wtJCaEJEdy85j2v+6sX8cmBlZUWXVQmsrGw4VpTAR0oLkIGl53HNX6WYMAyurKyUw8pMYGVlpRDFlQARXUxEh4noCBFdXVqeGIjoBiI6TkSHOtfOJKLbiOhB9/8L3HUioutcfu8logvKSe4HEZ1NRHcQ0f1EdB8RvctdX0QeiejZRHQnEX3T5e+97vp5RHTA5ePTRHSau366+/uI+/7cohlIpfWSKvEPwCkAvgvgJQBOA/BNAOeXlCkyH38A4AIAhzrX/gHA1e7z1QA+4D5fAuCLaE5u2g3gQGn5PfK3A8AF7vPzAHwHwPlLyaOT87nu8xYAB5zcNwPY665/GMCfuc9/DuDD7vNeAJ8unYek/Bcu/NcA+FLn72sAXFO6UCLzcm5PCRwGsMN93oHGFwIA/gXAZUP31fIPwC1ozqRcXB4B/BqAewC8Go1z0Knu+sm2CuBLAF7jPp/q7qPSssf+K70ceBGAH3X+fshdWwLb+amDWH8MYLv7XHWe3dT3lWhGy8XkkYhOIaKDAI4DuA3NDPVRZn7C3dLNw8n8ue8fA/DCrAILUloJbATcDBnVb8MQ0XMBfA7Au5n5593vas8jMz/JzLsAnAXgIgAvKytRPkorgaMAzu78fZa7tgQepqeOb9+BZoQBKs0zEW1BowA+ycyfd5cXlUcAYOZHAdyBZvp/BhG1rvXdPJzMn/v++QB+kldSOUorgbsA7HRW2NPQGFn2F5ZJiv0A9rnP+9Cso9vrlzsL+m4Aj3Wm1CahJvTtYwAeYOYPdb5aRB6JaBsRneE+PweNveMBNMrgre62fv7afL8VwFfcTKhOShsl0FiSv4NmDfY3peWJzMOnABwD8H9o1o5XoFkj3g7gQQBfBnCmu5cA/JPL77cAXFhafo/8vRbNVP9eAAfdv0uWkkcAvwvgGy5/hwD8rbv+EgB3AjgC4DMATnfXn+3+PuK+f0npPKT8Wz0GV1Y2nNLLgZWVlcKsSmBlZcNZlcDKyoazKoGVlQ1nVQIrKxvOqgRWVjacVQmsrGw4qxJYWdlw/h/N30NRJl9+qgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out_PIL)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dscience",
   "language": "python",
   "name": "dscience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
